{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HbvI8LO4RTi4",
        "outputId": "8d358211-213f-42a8-ec5b-00dd265f2a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 1.2386\n",
            "Epoch [2/100], Loss: 1.1290\n",
            "Epoch [3/100], Loss: 1.0417\n",
            "Epoch [4/100], Loss: 0.9712\n",
            "Epoch [5/100], Loss: 0.9113\n",
            "Epoch [6/100], Loss: 0.8580\n",
            "Epoch [7/100], Loss: 0.8093\n",
            "Epoch [8/100], Loss: 0.7643\n",
            "Epoch [9/100], Loss: 0.7223\n",
            "Epoch [10/100], Loss: 0.6829\n",
            "Epoch [11/100], Loss: 0.6461\n",
            "Epoch [12/100], Loss: 0.6123\n",
            "Epoch [13/100], Loss: 0.5815\n",
            "Epoch [14/100], Loss: 0.5537\n",
            "Epoch [15/100], Loss: 0.5285\n",
            "Epoch [16/100], Loss: 0.5057\n",
            "Epoch [17/100], Loss: 0.4849\n",
            "Epoch [18/100], Loss: 0.4659\n",
            "Epoch [19/100], Loss: 0.4484\n",
            "Epoch [20/100], Loss: 0.4323\n",
            "Epoch [21/100], Loss: 0.4175\n",
            "Epoch [22/100], Loss: 0.4036\n",
            "Epoch [23/100], Loss: 0.3907\n",
            "Epoch [24/100], Loss: 0.3786\n",
            "Epoch [25/100], Loss: 0.3671\n",
            "Epoch [26/100], Loss: 0.3561\n",
            "Epoch [27/100], Loss: 0.3457\n",
            "Epoch [28/100], Loss: 0.3362\n",
            "Epoch [29/100], Loss: 0.3275\n",
            "Epoch [30/100], Loss: 0.3194\n",
            "Epoch [31/100], Loss: 0.3119\n",
            "Epoch [32/100], Loss: 0.3049\n",
            "Epoch [33/100], Loss: 0.2986\n",
            "Epoch [34/100], Loss: 0.2927\n",
            "Epoch [35/100], Loss: 0.2871\n",
            "Epoch [36/100], Loss: 0.2819\n",
            "Epoch [37/100], Loss: 0.2770\n",
            "Epoch [38/100], Loss: 0.2727\n",
            "Epoch [39/100], Loss: 0.2688\n",
            "Epoch [40/100], Loss: 0.2651\n",
            "Epoch [41/100], Loss: 0.2614\n",
            "Epoch [42/100], Loss: 0.2580\n",
            "Epoch [43/100], Loss: 0.2551\n",
            "Epoch [44/100], Loss: 0.2525\n",
            "Epoch [45/100], Loss: 0.2502\n",
            "Epoch [46/100], Loss: 0.2479\n",
            "Epoch [47/100], Loss: 0.2456\n",
            "Epoch [48/100], Loss: 0.2435\n",
            "Epoch [49/100], Loss: 0.2417\n",
            "Epoch [50/100], Loss: 0.2400\n",
            "Epoch [51/100], Loss: 0.2384\n",
            "Epoch [52/100], Loss: 0.2368\n",
            "Epoch [53/100], Loss: 0.2352\n",
            "Epoch [54/100], Loss: 0.2338\n",
            "Epoch [55/100], Loss: 0.2326\n",
            "Epoch [56/100], Loss: 0.2315\n",
            "Epoch [57/100], Loss: 0.2304\n",
            "Epoch [58/100], Loss: 0.2293\n",
            "Epoch [59/100], Loss: 0.2283\n",
            "Epoch [60/100], Loss: 0.2274\n",
            "Epoch [61/100], Loss: 0.2266\n",
            "Epoch [62/100], Loss: 0.2258\n",
            "Epoch [63/100], Loss: 0.2251\n",
            "Epoch [64/100], Loss: 0.2244\n",
            "Epoch [65/100], Loss: 0.2237\n",
            "Epoch [66/100], Loss: 0.2230\n",
            "Epoch [67/100], Loss: 0.2224\n",
            "Epoch [68/100], Loss: 0.2219\n",
            "Epoch [69/100], Loss: 0.2213\n",
            "Epoch [70/100], Loss: 0.2208\n",
            "Epoch [71/100], Loss: 0.2203\n",
            "Epoch [72/100], Loss: 0.2199\n",
            "Epoch [73/100], Loss: 0.2195\n",
            "Epoch [74/100], Loss: 0.2190\n",
            "Epoch [75/100], Loss: 0.2187\n",
            "Epoch [76/100], Loss: 0.2183\n",
            "Epoch [77/100], Loss: 0.2180\n",
            "Epoch [78/100], Loss: 0.2176\n",
            "Epoch [79/100], Loss: 0.2173\n",
            "Epoch [80/100], Loss: 0.2170\n",
            "Epoch [81/100], Loss: 0.2167\n",
            "Epoch [82/100], Loss: 0.2165\n",
            "Epoch [83/100], Loss: 0.2162\n",
            "Epoch [84/100], Loss: 0.2160\n",
            "Epoch [85/100], Loss: 0.2157\n",
            "Epoch [86/100], Loss: 0.2155\n",
            "Epoch [87/100], Loss: 0.2153\n",
            "Epoch [88/100], Loss: 0.2151\n",
            "Epoch [89/100], Loss: 0.2149\n",
            "Epoch [90/100], Loss: 0.2147\n",
            "Epoch [91/100], Loss: 0.2145\n",
            "Epoch [92/100], Loss: 0.2144\n",
            "Epoch [93/100], Loss: 0.2142\n",
            "Epoch [94/100], Loss: 0.2140\n",
            "Epoch [95/100], Loss: 0.2138\n",
            "Epoch [96/100], Loss: 0.2137\n",
            "Epoch [97/100], Loss: 0.2135\n",
            "Epoch [98/100], Loss: 0.2133\n",
            "Epoch [99/100], Loss: 0.2131\n",
            "Epoch [100/100], Loss: 0.2129\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple RNN model\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        return out\n",
        "\n",
        "# Instantiate the model\n",
        "input_size = 10  # Replace with your input size\n",
        "hidden_size = 20  # Replace with your desired hidden size\n",
        "num_layers = 2  # Replace with the number of layers\n",
        "model = SimpleRNN(input_size, hidden_size, num_layers)\n",
        "\n",
        "# Define toy sequence data and target\n",
        "sequence = torch.randn(5, 3, input_size)  # Replace 5 with the batch size\n",
        "target = torch.randn(5, 3, hidden_size)  # Use hidden_size for the target\n",
        "\n",
        "# Loss and optimization\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(sequence)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6ql4YBPRTi9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}